{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposal Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import random\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import paddle.v2 as paddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(video_id, path='/mnt/BROAD-datasets/video/training/'):\n",
    "    \n",
    "    with open(path+video_id+'.pkl', 'rb') as f:\n",
    "        data = cPickle.load(f)\n",
    "    video_length = data.shape[0]\n",
    "    return data, video_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(json_path='/mnt/BROAD-datasets/video/meta.json'):\n",
    "    with open(json_path, 'r') as f:\n",
    "        json_content = json.load(f)\n",
    "    return json_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_video(video_id, labels):\n",
    "    data, video_length = load_video(video_id)\n",
    "    annotations = labels['database'][video_id]['annotations']\n",
    "    label = np.zeros([video_length])\n",
    "    for point in points:\n",
    "        label[int(point[0]):int(point[1])] = 1\n",
    "    return data, label, video_length\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_segments(video, label, window_size=10, stride=5, thresh=3):\n",
    "    \"\"\"\n",
    "    分段\n",
    "    \"\"\"\n",
    "    segments = [] # (data, label_forward, label_backward)\n",
    "    video_length = len(video)\n",
    "    num_segments = (video_length - window_size + stride) / stride\n",
    "    start = 0\n",
    "    for i in xrange(num_segments):\n",
    "        segment = video[start: start+window_size]\n",
    "        current_label = label[start: start+window_size]\n",
    "        start += stride\n",
    "        \n",
    "        if np.sum(current_label) > thresh:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "            \n",
    "#         forward_label = np.zeros([window_size])\n",
    "#         backward_label = np.zeros([window_size])\n",
    "#         k = 0\n",
    "#         while k < window_size and current_label[k] != 0:\n",
    "#             k += 1\n",
    "#             forward_label[k] = 1\n",
    "        \n",
    "#         k = window_size-1\n",
    "#         while k >= 0 and current_label[k] != 0:\n",
    "#             k = k - 1\n",
    "#             backward_label[k] = 1\n",
    "        segments.append((segment, label))\n",
    "    return segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reader():\n",
    "    \n",
    "#     with open('data.txt', 'r') as f:\n",
    "#         file_names = f.readlines()\n",
    "#     file_names = [x.rstrip('\\n\\r').replace('.pkl', '') for x in file_names]\n",
    "#     labels = load_labels()\n",
    "#     all_data = []\n",
    "#     for name in file_names:\n",
    "#         data, label, video_length = load_train_video(name, labels)\n",
    "#         segments = generate_segments(data, label)\n",
    "#         all_data = all_data.extend(segments)\n",
    "    \n",
    "    def reader():\n",
    "        # random.shuffle(all_data)\n",
    "        for i in xrange(1000):#len(all_data)):\n",
    "            yield np.random.rand(1,2048), np.random.randint(0,2)#np.array(all_data[i][0]), int(all_data[i][1])\n",
    "            \n",
    "    return reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(batch_input_seq):\n",
    "    \n",
    "    bidirectional_gru = paddle.networks.bidirectional_gru(\n",
    "        input=batch_input_seq,\n",
    "        size=512,\n",
    "        return_seq=True\n",
    "    )    \n",
    "    \n",
    "    fc_1 = paddle.layer.fc(\n",
    "        input=bidirectional_gru,\n",
    "        size=256,\n",
    "        act=paddle.activation.Relu()\n",
    "    )\n",
    "    \n",
    "    gru2 = paddle.networks.bidirectional_gru(\n",
    "        input=fc_1,\n",
    "        size=256,\n",
    "    )\n",
    "    output = paddle.layer.fc(\n",
    "        input=gru2,\n",
    "        size=2,\n",
    "        act=paddle.activation.Softmax()\n",
    "    )\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddle.v2.plot import Ploter\n",
    "train_title = \"Train cost\"\n",
    "test_title = \"Test cost\"\n",
    "cost_ploter = Ploter(train_title, test_title)\n",
    "step = 0\n",
    "sum_cost = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = paddle.layer.data(name='data', type=paddle.data_type.dense_vector_sequence(2048))\n",
    "is_train = True\n",
    "output = model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paddle.init(use_gpu=False, trainer_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVcCQaDmDFfkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118f30b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if is_train:\n",
    "    input_label = paddle.layer.data(name='label', type=paddle.data_type.integer_value(2))\n",
    "    cost = paddle.layer.classification_cost(input=output, label=input_label)\n",
    "    train_reader = create_reader()\n",
    "    train_reader = paddle.batch(reader=train_reader,batch_size=64)\n",
    "    feeding = {'data':0, 'label':1}\n",
    "    adam_optimizer = paddle.optimizer.Adam(learning_rate=1e-4,\n",
    "        regularization=paddle.optimizer.L2Regularization(rate=8e-4),\n",
    "        model_average=paddle.optimizer.ModelAverage(average_window=0.5))\n",
    "    parameters = paddle.parameters.create(cost)\n",
    "    trainer = paddle.trainer.SGD(cost=cost,parameters=parameters,update_equation=adam_optimizer)\n",
    "    \n",
    "    def event_handler(event):\n",
    "        global step\n",
    "        global sum_cost\n",
    "        \n",
    "        if isinstance(event, paddle.event.EndIteration):\n",
    "            sum_cost += event.cost\n",
    "            if step % 10 == 0:  # every 10 batches, record a train cost\n",
    "                cost_ploter.append(train_title, step, event.cost)\n",
    "            if event.batch_id % 20 == 0:\n",
    "                print \"\\nPass %d, Batch %d, AVG_COST: %f, %s\" % (\n",
    "                    event.pass_id, event.batch_id, sum_cost/(event.batch_id+1), event.metrics)\n",
    "            else:\n",
    "                sys.stdout.write('.')\n",
    "                sys.stdout.flush()\n",
    "        if isinstance(event, paddle.event.EndPass):\n",
    "            sum_cost = 0.0\n",
    "            with open('/home/kesci/work/params.tar', 'w') as f:\n",
    "                parameters.to_tar(f)\n",
    "        if step % 100 == 0:\n",
    "            cost_ploter.plot()\n",
    "        step += 1\n",
    "    \n",
    "    trainer.train(reader=train_reader,event_handler=event_handler,feeding=feeding,num_passes=10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nms_detection(proposals, scores, overlap=0.7):\n",
    "    \"\"\"Non-maximum suppression: Greedily select high-scoring detections and\n",
    "    skip detections that are significantly covered by a previously selected\n",
    "    detection. This version is translated from Matlab code by Tomasz\n",
    "    Malisiewicz, who sped up Pedro Felzenszwalb's code.\n",
    "    Parameters\n",
    "    ----------\n",
    "    props : ndarray\n",
    "        Two-dimensional array of shape (num_props, 2), containing the start and\n",
    "        end boundaries of the temporal proposals.\n",
    "    scores : ndarray\n",
    "        One-dimensional array of shape (num_props,), containing the corresponding\n",
    "        scores for each detection above.\n",
    "    Returns\n",
    "    -------\n",
    "    nms_props, nms_scores : ndarrays\n",
    "        Arrays with the same number of dimensions as the original input, but\n",
    "        with only the proposals selected after non-maximum suppression.\n",
    "    \"\"\"\n",
    "    t1 = props[:, 0]\n",
    "    t2 = props[:, 1]\n",
    "    ind = np.argsort(scores)\n",
    "    area = (t2 - t1 + 1).astype(float)\n",
    "    pick = []\n",
    "    while len(ind) > 0:\n",
    "        i = ind[-1]\n",
    "        pick.append(i)\n",
    "        ind = ind[:-1]\n",
    "        tt1 = np.maximum(t1[i], t1[ind])\n",
    "        tt2 = np.minimum(t2[i], t2[ind])\n",
    "        wh = np.maximum(0., tt2 - tt1 + 1.0)\n",
    "        o = wh / (area[i] + area[ind] - wh)\n",
    "        ind = ind[np.nonzero(o <= overlap)[0]]\n",
    "    nms_props, nms_scores = props[pick, :], scores[pick]\n",
    "    return nms_props, nms_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(video_id, parameters):\n",
    "    \n",
    "    video, video_length = load_video(video_id, '/mnt/BROAD-datasets/video/testing/')\n",
    "    \n",
    "    segments = []\n",
    "    window_size = 10\n",
    "    num_segments = video_length/window_size\n",
    "    start = 0\n",
    "    for i in xrange(num_segments):\n",
    "        segment = video[start: start+window_size]\n",
    "        start += window_size\n",
    "        segments.append((segment,))\n",
    "    \n",
    "    probs = paddle.infer(output_layer=output, parameters=parameters, input=segments, feeding={'data': 0})\n",
    "    \n",
    "    return probs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(prediction, probs):\n",
    "    window_size = 10\n",
    "    # result: [((start, end),prob),....]\n",
    "    result = []\n",
    "    \n",
    "    current_start = -1\n",
    "    current_end = 0\n",
    "    # 间隔空白\n",
    "    blank_threshhold = 2\n",
    "    # 最小长度\n",
    "    min_lengths = 1\n",
    "    \n",
    "    state = 0\n",
    "    # state = 0 未找到start\n",
    "    # state = 1 找到start，未找到end, 当前值为1\n",
    "    # state = 2 找到start，未找到end, 当前值为0\n",
    "    # state = 3 中间隔了很多空白\n",
    "\n",
    "    for i in xrange(prediction.shape[0]):\n",
    "        if state == 0 and prediction[i] == 1:\n",
    "            \n",
    "            current_start = i\n",
    "            state = 1\n",
    "            continue\n",
    "            \n",
    "        if state == 1 and prediction[i] == 1:\n",
    "            \n",
    "            current_end = i\n",
    "            continue\n",
    "        \n",
    "        if state == 1 and prediction[i] == 0:\n",
    "            \n",
    "            state = 2\n",
    "            continue\n",
    "        \n",
    "        if state == 2 and prediction[i] == 1:\n",
    "            \n",
    "            distance = i - current_end\n",
    "            if distance > blank_threshhold:\n",
    "                \n",
    "                length = current_end - current_start + 1\n",
    "                state = 0\n",
    "                if length <= min_lengths:\n",
    "                    current_start = -1\n",
    "                    current_end = -1\n",
    "                    continue\n",
    "                prob = sum(probs[current_start: current_end+1])/length\n",
    "                result.append(([current_start*window_size, current_end*window_size],prob))\n",
    "                current_start = -1\n",
    "                current_end = -1\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                if distance < blank_threshhold/2:\n",
    "                    current_end = i\n",
    "                    state = 1\n",
    "                    continue\n",
    "                else:\n",
    "                    state = 3\n",
    "                    continue\n",
    "                    \n",
    "        if state == 3 and prediction[i] == 1:\n",
    "            current_end = i\n",
    "            state = 1\n",
    "            continue\n",
    "        \n",
    "        if state == 3 and prediction[i] == 0:\n",
    "            \n",
    "            length = current_end - current_start + 1\n",
    "\n",
    "            state = 0\n",
    "            if length <= min_lengths:\n",
    "                current_start = -1\n",
    "                current_end = -1\n",
    "                continue\n",
    "            prob = sum(probs[current_start: current_end+1])/length\n",
    "            result.append(([current_start*window_size, current_end*window_size],prob))\n",
    "\n",
    "            current_start = -1\n",
    "            current_end = -1\n",
    "            continue\n",
    "    \n",
    "    if state == 1 and current_start != -1:\n",
    "        current_end = len(prediction)\n",
    "        length = current_end - current_start + 1\n",
    "        if length <= min_lengths:\n",
    "            current_start = -1\n",
    "            current_end = -1\n",
    "            return result\n",
    "        prob = sum(probs[current_start: current_end+1])/length\n",
    "        result.append(([current_start*window_size, current_end*window_size],prob))\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_result(probs):\n",
    "    prediction = np.argmax(prrob, axis=1)\n",
    "    predict_right_prob = prrob[:,1]\n",
    "    data = aggregate(prediction, predict_right_prob)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_all():\n",
    "    infer_result = dict()\n",
    "    counter = 0\n",
    "    \n",
    "    with open('/home/kesci/work/params.tar', 'r') as f:\n",
    "        parameters = paddle.parameters.Parameters.from_tar(f)\n",
    "\n",
    "    infer_result = dict()\n",
    "    counter = 0\n",
    "    for video_file in test_files_lines:\n",
    "        video_id = video_file.split('.')[0]\n",
    "        prob = inference(video_id, parameters)\n",
    "        infer_result[video_id] = prob\n",
    "        counter += 1\n",
    "        print(\"[%s/%s]finish: %s\" % (counter, len(test_files_lines), video_id))\n",
    "    return infer_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_handle(infer_result):\n",
    "    result = dict()\n",
    "    for key in probs.keys():\n",
    "        prrob = probs[key]\n",
    "        data = generate_result(prrob)\n",
    "        result[key] = data\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_result_file(data, filepath, version='VERSION 1.0'):\n",
    "    result = dict()\n",
    "    result['version'] = version\n",
    "    \n",
    "    results = dict()\n",
    "    \n",
    "    for key in data.keys():\n",
    "        \n",
    "        tmp_result = []\n",
    "        for seg in data[key]:\n",
    "            tmp_dict = dict()\n",
    "            tmp_dict['score'] = seg[1]\n",
    "            tmp_dict['segment'] = seg[0]\n",
    "            tmp_result.append(tmp_dict)\n",
    "        results[key] = tmp_result\n",
    "    \n",
    "    result['results'] = results\n",
    "    \n",
    "    r = json.dumps(result)\n",
    "    print(r)\n",
    "    with open(filepath, 'w+') as f:\n",
    "        f.write(r)\n",
    "    print(\"generate finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_result = inference_all()\n",
    "print(\"Finish Inference\")\n",
    "result = post_handle(in_result)\n",
    "print(\"Finish Post Handle\")\n",
    "generate_result_file(result, 'v2.json')\n",
    "print(\"Finish Genenrate\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
